- name: Create VM {{ vm_config.inventory_hostname }}
  register: vm_result
  community.general.proxmox_kvm:
    api_host: "{{ ansible_host }}"
    api_user: "{{ proxmox_api_user }}"
    api_token_id: "{{ proxmox_api_token_id }}"
    api_token_secret: "{{ proxmox_api_token_secret }}"
    node: "{{ inventory_hostname }}"
    name: "{{ vm_config.inventory_hostname }}"
    vmid: "{{ vm_config.vm_id }}"
    description: "{{ cluster_name }} k3s {{ 'control plane' if vm_config.inventory_hostname in groups['k3s_servers'] else 'worker' }} node on vlan {{ vm_config.vlan_id }}"
    tags:
      - "{{ 'k3s-control-plane' if vm_config.inventory_hostname in groups['k3s_servers'] else 'k3s-worker' }}"
      - "k3s"
      - "{{ cluster_name | lower }}"
    onboot: true

    # Hardware configuration
    memory: "{{ vm_config.vm_memory_mb }}"
    cores: "{{ vm_config.vm_cpu_cores }}"
    hostpci:
      # GPU passthrough if gpu_type is set
      hostpci0: "{{ 'mapping=' + proxmox_gpu_mapped_device if vm_config.gpu_type is defined else omit }}"
    machine: q35  # Necessary for GPU passthrough
    serial:
      serial0: socket
    bios: ovmf

    # Disk configuration
    # virtio:
    #   virtio0: "{{ proxmox_vm_storage }}:{{ vm_config.vm_disk_gb }}"
    boot: order=virtio0
    scsihw: virtio-scsi-pci
    ide:
      ide2: "{{ proxmox_vm_storage }}:cloudinit,format=raw"
    efidisk0:
      storage: "{{ proxmox_vm_storage }}"
      format: raw
      efitype: 4m
      pre_enrolled_keys: false

    # See below, importing images from storage locations isn't supported yet
    # virtio:
    #   virtio0: "{{ proxmox_vm_storage }}:0,iothread=1,discard=on,import-from={{ proxmox_image_storage }}:iso/{{ cloud_image_name }},format=qcow2"

    # Cloud-Init settings
    net:
      net0: "virtio,bridge={{ network_bridge }},tag={{ vm_config.vlan_id }}"
    sshkeys: "{{ lookup('file', '~/.ssh/id_rsa.pub') }}"
    ipconfig:
      ipconfig0: "ip={{ vm_config.ansible_host }}/{{ vm_config.netmask_cidr }},gw={{ vm_config.network_gateway }}"
    ciuser: "{{ ansible_user }}"
    cipassword: "{{ vm_default_password }}"
    nameservers: "{{ vm_config.dns_servers }}"

# This task has to run as the root user, not an API token, in order to use an absolute path for disk import.
# Importing qcow2 images through the API isn't supported yet. Follow this thread:
# https://forum.proxmox.com/threads/import-disk-from-file-using-api.93393/
# Once importing images is supported, remove this block and uncomment the virtio0 line above.
- name: Attach {{ vm_config.inventory_hostname }} cloud image root disk
  community.general.proxmox_disk:
    api_host: "{{ ansible_host }}"
    api_user: "{{ proxmox_api_user }}"
    api_password: "{{ vault_proxmox_root_password }}"
    vmid: "{{ vm_result.vmid }}"
    import_from: "/mnt/pve/{{ proxmox_image_storage }}/template/iso/{{ cloud_image_name }}"
    disk: virtio0
    storage: "{{ proxmox_vm_storage }}"
    discard: "on"

- name: Resize {{ vm_config.inventory_hostname }} root disk
  community.general.proxmox_disk:
    api_host: "{{ ansible_host }}"
    api_user: "{{ proxmox_api_user }}"
    api_token_id: "{{ proxmox_api_token_id }}"
    api_token_secret: "{{ proxmox_api_token_secret }}"
    vmid: "{{ vm_result.vmid }}"
    disk: virtio0
    size: "{{ vm_config.vm_disk_gb }}G"
    state: resized

- name: Attach {{ vm_config.inventory_hostname }} Longhorn storage disk
  when: vm_config.inventory_hostname in groups['k3s_agents']
  community.general.proxmox_disk:
    api_host: "{{ ansible_host }}"
    api_user: "{{ proxmox_api_user }}"
    api_token_id: "{{ proxmox_api_token_id }}"
    api_token_secret: "{{ proxmox_api_token_secret }}"
    vmid: "{{ vm_result.vmid }}"
    disk: virtio1
    size: "{{ vm_config.longhorn_disk_gb }}"
    storage: "{{ proxmox_vm_storage }}"
    format: raw

- name: Start {{ vm_config.inventory_hostname }} VM
  community.general.proxmox_kvm:
    api_host: "{{ ansible_host }}"
    api_user: "{{ proxmox_api_user }}"
    api_token_id: "{{ proxmox_api_token_id }}"
    api_token_secret: "{{ proxmox_api_token_secret }}"
    node: "{{ inventory_hostname }}"
    vmid: "{{ vm_result.vmid }}"
    state: started

- name: Wait for {{ vm_config.inventory_hostname }} VM to start
  wait_for:
    host: "{{ vm_config.ansible_host }}"
    port: 22
    timeout: 300
    state: started
  delegate_to: localhost
  delegate_facts: true
